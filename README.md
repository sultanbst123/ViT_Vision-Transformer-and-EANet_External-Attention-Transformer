# ViT_Vision-Transformer-and-EANet_External-Attention-Transformer

## Vision Transformer(ViT)

<p align="center">
 <img src="https://github.com/sultanbst123/ViT_Vision-Transformer-and-EANet_External-Attention-Transformer/blob/main/images.png"> <i>Vision Transformer Architecture</i>
</p>

Vision Transformer(ViT) adalah model untuk klasifikasi citra(image classification) yang mempekerjakan Transformer arsitektur. Gambar dipecah menjadi tambalan berukuran tetap, masing-masing kemudian disematkan secara linier, penyematan posisi ditambahkan, dan urutan vektor yang dihasilkan diumpankan ke enkoder Transformer standar, Untuk melakukan klasifikasi.

## External Attention Transformer

Model EANet hanya mengganti Self-Attention, perbedaan antara Self-Attention dan External-Attention adalah  Perhatian eksternal(External Attention) memiliki kompleksitas linier dan secara implisit mempertimbangkan korelasi antara semua sampel data sementara  
Self-Attention memiliki kompleksitas kuadrat dan mengabaikan potensi korelasi antara sampel yang berbeda.

## Referensi 


